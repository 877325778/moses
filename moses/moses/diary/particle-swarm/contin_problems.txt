Initial experiments for PS and HC in continuous problems.
Published on July 26th 2015.

For resume version jump to 3.4. General.
1. Methodology:
First, the experiments were divided in two groups: without reduction (-B 0 -E 1 parameters) and with reduction; it's separated this way because the reduction part affects the particle swarm (PS) too much (clean_combo_tree uses 99.73% with reduction in PS). Besides that, the experiments were split in three parts: analysis of the memory, processing and time. The memory analysis was done using the valgrind tool massif running for 4 values of depth {5(default), 16, 32, 128} and for PS and hill climbing (HC). The processing analysis was done in the same way of the memory, but using the tool callgrind. The time analysis was done in a different way, using a simple python script to measure the mean time of seeds between 1 and 10 running between depth 2 and 32 for PS and HC. The dataset used was predicates.csv because it is a simple one that is already inside the examples folder of Moses; It was running for a maximum of 1000 evaluations, a small value because of the valgrind tools that increase the program time in 20x for massif and between 20x and 100x for callgring [1] but it's a sufficient amount of evaluations to test (HC in some seeds can find the best solution in less than 1000 evals).
2. Results description:
2.1. Memory:
PS with reduction spend more memory than without.
Increasing in the depth of PS, increases the memory used, but not that much, sometimes it can decrease, because it can find better results that are less complex.
HC without reduction reaches the ram limit independently of depth.
HC with reduction uses far less memory, even less than PS without reduction.
2.2. Processing:
Variable length representation affects PS without reduction too much depending of the depth (15% at depth 32 vs. 2.7% in depth 5).
Affects the PS with reduction in a similar way, but with a percentage much lower, because of the reduction.
The depth didn't affect hill climbing at all, mostly because it found a solution that needs less than depth 5.
2.3. Time:
PS without reduction is much quicker than with reduction.
HC without reduction is slower than with reduction.
PS without reduction is quicker than HC without reduction.
PS with reduction is very much slower than HC with reduction.
2.4. Others:
Increasing the depth in PS, it returns better results, but it's stuck in the discrete maximum local anyway.
The results are not affected increasing the HC depth, maybe because this problem didn't need precision or a bigger value to reach the max. global.
3. Conclusion:
3.1. Memory:
I don't think that memory is a problem, even very complex problems with thousands of instances will not reach the amount of ram that the computers today have, and even if do, there's always feature selection; but let's take a look:
Variable-length representation uses a amount of 28B (4B depth, 8B mean, 8B step_size, 8B expansion) + ((1/4B * depth) * num_instances) for each dimension in a deme. While a double representation uses 8B * num_instances. So using variable-length representation with a small depth for a larger number of instances still makes sense for RAM economy. But i'm still felling that this way could be better in 2 forms. 1- It uses 2 bits to represent left, right and stop (0,1,2), and it don't use 11 (3). 2- 5 depth can represents +-30 (with LLLLS and RRRRS), why not use until LLLLL or RRRRR if the get/set contin function limits the for with the depth too?
3.2. Processing:
With variable length representation, processing is just a problem with PS, and just if it have a bigger depth. In all cases the clean_combo_tree and merge_demes are the ones that use more processing and the specific part of HC or PS are small (PS is bigger just because of set_contin and get_contin). In the PS i'm having to call get_contin a lot of times (to get the best values), and it isn't helping. To solve it i'll have to store the values in doubles, that in the end will lose the benefices of using the variable length representation.
3.3 Time:
I don't know how the cache of combo trees reduction works, but it seems to work best with HC where each one in a eval are very close. In the initial phase of PS the instance are very different one of the other. I would say that PS just is running quicker without reduction because it returns a deme smaller than HC because it doesn't include the worst solutions.
3.4. General:
The variable length representation don't have that much impact in memory or performance, it just have when using PS and for complex problems. Even so, I still find better to change it to a double representation, to get a little better performance, with the possibility to search in a bigger space and have a less complex code at the cost of a little more ram and my work.
Detailed results data:
1. PS without reduction:
1.1. Massif:
depth 5: peak 1.2842 MiB = 0.168322662 MB
depth 16: peak 1.3022 MiB = 0.170681958 MB
depth 32: peak 1.1866 MiB = 0.155530035 MB (leads to better solutions, and than, less complexity)
depth 128: peak 1.5212 MiB = 0.199386726 MB
1.2. Callgrind:
depth 5:
get_contin: 1.95%
set_contin: 0.7%
update_particles: 3.17%
complexitybasedscorer: 80.65%
depth 16:
get_contin: 5.39%
set_contin: 1.97%
update_particles: 6.98%
complexitybasedscorer: 77.19%
depth 32:
get_contin: 11.02%
set_contin: 4.15%
update_particles: 14.16%
complexitybasedscorer: 77.30%
depth 128:
get_contin: 16.18%
set_contin: 10.34%
update_particles: 24.40%
complexitybasedscorer: 67.82%
1.3. Time (s):
Depth: 2 | Mean: 2.557880
Depth: 3 | Mean: 2.593005
Depth: 4 | Mean: 2.663667
Depth: 5 | Mean: 2.668498
Depth: 6 | Mean: 2.701040
Depth: 7 | Mean: 2.644231
Depth: 8 | Mean: 2.714792
Depth: 9 | Mean: 2.692005
Depth: 10 | Mean: 2.680957
Depth: 11 | Mean: 2.735071
Depth: 12 | Mean: 2.783216
Depth: 13 | Mean: 2.743773
Depth: 14 | Mean: 2.725607
Depth: 15 | Mean: 2.722347
Depth: 16 | Mean: 2.755987
Depth: 17 | Mean: 2.901231
Depth: 18 | Mean: 2.809483
Depth: 19 | Mean: 2.762999
Depth: 20 | Mean: 2.758817
Depth: 21 | Mean: 2.772569
Depth: 22 | Mean: 2.816113
Depth: 23 | Mean: 2.928664
Depth: 24 | Mean: 2.904253
Depth: 25 | Mean: 2.938958
Depth: 26 | Mean: 2.845138
Depth: 27 | Mean: 2.877145
Depth: 28 | Mean: 2.857758
Depth: 29 | Mean: 2.840159
Depth: 30 | Mean: 2.822597
Depth: 31 | Mean: 2.813350
Depth: 32 | Mean: 2.820256
2. HC without reduction:
2.1. Massif:
depth 5: peak 53.1730 MiB = 6.96949146 MB
depth 16: peak 53.1730 MiB = 6.96949146 MB
depth 32: peak 53.1730 MiB = 6.96949146 MB
depth 128: peak 53.1730 MiB = 6.96949146 MB
2.2. Callgrind:
depth 5:
get_contin: 0.78%
set_contin: 0%
hill_climbing: 0.05%
complexitybasedscorer: 65.23%
depth 16:
get_contin: 0.78%
set_contin: 0%
hill_climbing: 0.05%
complexitybasedscorer: 65.21%
depth 32:
get_contin: 0.78%
set_contin: 0%
hill_climbing: 0.05%
complexitybasedscorer: 65.23%
depth 128:
get_contin: 0.78%
set_contin: 0%
hill_climbing: 0.06%
complexitybasedscorer: 65.20%
2.3. Time (s):
Depth: 2 | Mean: 13.933148
Depth: 3 | Mean: 13.710301
Depth: 4 | Mean: 13.771378
Depth: 5 | Mean: 13.699602
Depth: 6 | Mean: 13.643018
Depth: 7 | Mean: 13.953615
Depth: 8 | Mean: 14.218726
Depth: 9 | Mean: 14.607479
Depth: 10 | Mean: 14.577442
Depth: 11 | Mean: 14.953429
Depth: 12 | Mean: 14.705942
Depth: 13 | Mean: 14.993052
Depth: 14 | Mean: 14.541223
Depth: 15 | Mean: 14.249910
Depth: 16 | Mean: 14.563872
Depth: 17 | Mean: 15.361906
Depth: 18 | Mean: 14.469012
Depth: 19 | Mean: 14.755074
Depth: 20 | Mean: 14.411482
Depth: 21 | Mean: 14.821014
Depth: 22 | Mean: 14.412988
Depth: 23 | Mean: 14.660408
Depth: 24 | Mean: 14.989600
Depth: 25 | Mean: 14.081191
Depth: 26 | Mean: 14.491643
Depth: 27 | Mean: 14.121354
Depth: 28 | Mean: 14.673866
Depth: 29 | Mean: 14.079422
Depth: 30 | Mean: 13.745444
Depth: 31 | Mean: 13.860764
3. PS with reduction:
3.1. Massif:
depth 5: peak 2.7437 MiB = 0.359622246 MB
depth 16: peak 2.8201 MiB = 0.369636147 MB
depth 32: peak 4.2963 MiB = 0.563124634 MB
depth 128: peak 3.6244 MiB = 0.475057357 MB
3.2. Callgrind:
depth 5:
get_contin: 0.11%
set_contin: 0.01%
update_particles: 0.02%
complexitybasedscorer: 91.94%
depth 16:
get_contin: 0.11%
set_contin: 0.02%
update_particles: 0.06%
complexitybasedscorer: 93.25%
depth 32:
get_contin: 0.12%
set_contin: 0.04%
update_particles: 0.15%
complexitybasedscorer: 91.06%
depth 128:
get_contin: 0.25%
set_contin: 0.16%
update_particles: 0.37%
complexitybasedscorer: 92.87%
3.3. Time (s):
Depth: 32 | Mean: 180
4. HC with reduction:
4.1. Massif:
depth 32: peak 940.1328 MiB = 0.1203369984 MB
4.2. Callgrind:
depth 32:
get_contin: 0.42%
set_contin: 0%
hill_climbing: 0.08%
complexitybasedscorer: 32.52% (Low because merge_demes uses a lot)
4.3. Time (s):
Depth: 32 | Mean: 1.8413
For even more detailed result (the callgrids and massifs outputs or time with results) you can just ask me, i'll not but it in the github, it's too big and don't need to be there.
[1] See valgrind site: http://valgrind.org/info/tools.html
